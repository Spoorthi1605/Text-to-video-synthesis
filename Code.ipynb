{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCYqjX-i1aPX"
      },
      "outputs": [],
      "source": [
        "!pip cache purge\n",
        "!pip install --no-cache-dir pytesseract opencv-python PyPDF2 spacy sentence-transformers nltk gtts moviepy diffusers torch transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "id": "jFNf0hQF18hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from time import time\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips\n",
        "import pytesseract as pyt\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import OrderedDict\n"
      ],
      "metadata": {
        "id": "dyeVk3q12AnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = r'/content/story3.png'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    print(\"Error: Image not loaded. Check the file path.\")\n",
        "else:\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aoGPmuyK2KoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "shL-2rOgk-y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load spaCy NLP Model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class TextExtract:\n",
        "    def filter_img(self, img):\n",
        "        _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "        return img\n",
        "\n",
        "    def clean_text(self, txt):\n",
        "        txt = re.sub(r'[^\\w\\s.,:;!?-]', '', txt)\n",
        "        txt = re.sub(r'\\s+', ' ', txt).strip()\n",
        "        return txt if txt else None\n",
        "    def extract_text_with_confidence(self, img):\n",
        "        details = pyt.image_to_data(img, lang=\"eng\", output_type=pyt.Output.DICT)\n",
        "        text_lines = []\n",
        "        line_text = []\n",
        "        last_y = -1\n",
        "\n",
        "        for i, word in enumerate(details['text']):\n",
        "            confidence = int(details['conf'][i])\n",
        "            y_pos = details['top'][i]\n",
        "            if confidence > 60 and word.strip():\n",
        "                if last_y == -1 or abs(last_y - y_pos) < 10:\n",
        "                    line_text.append(word)\n",
        "                else:\n",
        "                    text_lines.append(' '.join(line_text))\n",
        "                    line_text = [word]\n",
        "                last_y = y_pos\n",
        "\n",
        "        if line_text:\n",
        "            text_lines.append(' '.join(line_text))\n",
        "\n",
        "        return \"\\n\".join(text_lines)\n",
        "\n",
        "    def img2txt(self, img_path, apply_filter=False, exe_time=False):\n",
        "        try:\n",
        "            start = time()\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                raise ValueError(\"Invalid image path or unreadable image format.\")\n",
        "\n",
        "            if apply_filter:\n",
        "                img = self.filter_img(img)\n",
        "\n",
        "            text = self.extract_text_with_confidence(img)\n",
        "            cleaned_text = self.clean_text(text)\n",
        "            #print(cleaned_text)\n",
        "            if exe_time:\n",
        "                print(f'Execution Time: {(time() - start) * 1000:.2f} ms')\n",
        "\n",
        "            return cleaned_text\n",
        "        except Exception as e:\n",
        "            print(f'Error: {e}')\n",
        "            return None\n",
        "ocr=TextExtract()\n",
        "text=ocr.img2txt(image_path)\n",
        "text"
      ],
      "metadata": {
        "id": "hbelpwXy2W-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Set your Gemini API key\n",
        "genai.configure(api_key=\"AIzaSyD91SD0iJM4Ca-hvlDg4pBqAkSm05kQp7Q\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "\n",
        "story_text = \"\"\"\n",
        "Fear. There was a lion who feared nothing except the crowing of cocks, A chill would go down his spine whenever he heard a cock crowing. One day he confessed his fear to the elephant, who was greatly amused. How can the crowing of a cock hurt you? he asked the lion, Think about it! Just then a mosquito began circling the head, frightening him out of his wits. If it gets into my ear Im he shrieked, flailing at the insect with his trunk. Now it was the turn to feel amused. Moral: If we could see our fears as others see them we would realise that most of our fears make no sense!\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Replace all pronouns with their correct corresponding character names based on story context dont add any thing outside the given text. Do not change anything else in the story.\n",
        "\n",
        "Story:\n",
        "{story_text}\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "text=response.text\n",
        "print(text)\n",
        "#print(response.text)\n"
      ],
      "metadata": {
        "id": "cgsFPFGPufNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scene generation\n"
      ],
      "metadata": {
        "id": "u8-TnfUp6GCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy + BERT + LDA"
      ],
      "metadata": {
        "id": "BZgARo3-LbxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def segment_scenes_with_bert_spacy_lda(text, eps=0.3, min_samples=1, n_topics=3):\n",
        "    \"\"\"Segments the story into meaningful scenes while preserving order.\"\"\"\n",
        "\n",
        "    lines = text.strip().split(\"\\n\")\n",
        "    remaining_text = \"\\n\".join(lines[:])\n",
        "\n",
        "    # Separate story and moral\n",
        "    moral_keyword = \"moral\"\n",
        "    moral_index = remaining_text.lower().find(moral_keyword)\n",
        "\n",
        "    if moral_index != -1:\n",
        "        story_text = remaining_text[:moral_index].strip()\n",
        "        moral_text = remaining_text[moral_index:].strip()\n",
        "    else:\n",
        "        story_text = remaining_text.strip()\n",
        "        moral_text = \"\"\n",
        "\n",
        "    # Tokenize sentences\n",
        "    story_sentences = sent_tokenize(story_text)\n",
        "\n",
        "    # Generate BERT Embeddings\n",
        "    embeddings = bert_model.encode(story_sentences)\n",
        "\n",
        "    # DBSCAN Clustering (Grouping Similar Sentences)\n",
        "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n",
        "    labels = clustering.fit_predict(embeddings)\n",
        "\n",
        "    # LDA Topic Modeling\n",
        "    vectorizer = CountVectorizer()\n",
        "    sentence_term_matrix = vectorizer.fit_transform(story_sentences)\n",
        "    lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
        "    lda_labels = lda_model.fit_transform(sentence_term_matrix).argmax(axis=1)\n",
        "\n",
        "    # Organizing Sentences into Scenes in Correct Order\n",
        "    scene_dict = OrderedDict()\n",
        "    sentence_order = {}\n",
        "\n",
        "    for idx, sentence in enumerate(story_sentences):\n",
        "        scene_label = (labels[idx], lda_labels[idx])\n",
        "\n",
        "        if scene_label not in scene_dict:\n",
        "            scene_dict[scene_label] = []\n",
        "            sentence_order[scene_label] = idx\n",
        "\n",
        "        scene_dict[scene_label].append(sentence)\n",
        "\n",
        "    # Sort Scenes by First Appearance\n",
        "    sorted_scenes = sorted(scene_dict.items(), key=lambda x: sentence_order[x[0]])\n",
        "\n",
        "    # Convert ordered scenes into text\n",
        "    scenes = [\" \".join(scene[1]) for scene in sorted_scenes]\n",
        "\n",
        "    if moral_text:\n",
        "        scenes.append(moral_text)\n",
        "\n",
        "    print(scenes)\n",
        "    return scenes\n",
        "scenes=segment_scenes_with_bert_spacy_lda(text)\n",
        "scenes"
      ],
      "metadata": {
        "id": "EtyQUKmDj8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "\n",
        "# Configure your Gemini API Key\n",
        "genai.configure(api_key='AIzaSyCLlWZK_DuviohR5JFgnGuXvJo3db7N2UE')  # Replace with your actual key\n",
        "\n",
        "# Initialize Gemini model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "def rewrite_scene_with_gemini(scene):\n",
        "    '''prompt = (\n",
        "        f\"Rewrite the following scene from a children's story in vivid, detailed, and visually rich language, \"\n",
        "        f\"so it can be used to generate a realistic image:\\n\\n\"\n",
        "        f\"Original scene: \\\"{scene}\\\"\\n\\n\"\n",
        "        f\"Detailed visual description:\"\n",
        "    )'''\n",
        "    prompt = (\n",
        "        f\"You are helping rewrite scenes from a children's story to prepare them for realistic AI image generation.\\n\"\n",
        "        f\"Take the following brief scene and rewrite it in vivid, visually detailed language that shows exactly what's happening visually.\\n\\n\"\n",
        "        f\"Scene: \\\"{scene}\\\"\\n\\n\"\n",
        "        f\"Detailed visual description:\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        #model.score()\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Rewrite all scenes with sleep between API calls\n",
        "rewritten_scenes = []\n",
        "for scene in scenes:\n",
        "    rewritten = rewrite_scene_with_gemini(scene)\n",
        "    rewritten_scenes.append(rewritten)\n",
        "    time.sleep(15)  # Pause for 2 seconds to respect API rate limits\n",
        "\n",
        "# Output\n",
        "for i, scene in enumerate(rewritten_scenes):\n",
        "    print(f\"\\nScene {i+1}:\\n{scene}\\n\")\n"
      ],
      "metadata": {
        "id": "RbVzLkJIsW9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google\"\n",
        "!pip install -U -q \"google.genai\"\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "os.environ[\"AIzaSyDoowqs_-FnpoYSIsaXCwDJOykZo_ABH78\"] = \"AIzaSyDoowqs_-FnpoYSIsaXCwDJOykZo_ABH78\"\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Google AI Studio/story/images\")"
      ],
      "metadata": {
        "id": "mi0NkG1G1Xzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "import mimetypes\n",
        "import time\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "def save_binary_file(file_name, data):\n",
        "    with open(file_name, \"wb\") as f:\n",
        "        f.write(data)\n",
        "\n",
        "def generate(rewritten_scenes):\n",
        "    client = genai.Client(\n",
        "        api_key=\"AIzaSyCRCvGxEMCt7rwvaAK2cILBPoL-_2CuNnY\",\n",
        "    )\n",
        "    image_paths=[]\n",
        "    model = \"imagen-3.0-generate-002\"\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=1,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_output_tokens=8192,\n",
        "        #response_modalities=[\"image\"],\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "\n",
        "    delay = 6  # Initial delay in seconds\n",
        "\n",
        "    for i, scene in enumerate(rewritten_scenes):\n",
        "        contents = [\n",
        "            types.Content(\n",
        "                role=\"user\",\n",
        "                parts=[types.Part.from_text(text=f\"generate 3d animated image of {scene} by maintaining character consistency,scene description and also keep small details intact and also generate only images without text in it\")],\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        success = False\n",
        "        retries = 3  # Max retries if quota is exceeded\n",
        "        while not success and retries > 0:\n",
        "            try:\n",
        "                for chunk in client.models.generate_content_stream(\n",
        "                    model=model,\n",
        "                    contents=contents,\n",
        "                    config=generate_content_config,\n",
        "                ):\n",
        "                    if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:\n",
        "                        continue\n",
        "                    if chunk.candidates[0].content.parts[0].inline_data:\n",
        "                        file_name = f\"scene_{i+1}\"\n",
        "                        inline_data = chunk.candidates[0].content.parts[0].inline_data\n",
        "                        file_extension = mimetypes.guess_extension(inline_data.mime_type)\n",
        "                        save_binary_file(f\"{file_name}{file_extension}\", inline_data.data)\n",
        "                        print(f\"File of mime type {inline_data.mime_type} saved to: {file_name}{file_extension}\")\n",
        "                        success = True\n",
        "                        image_path=\"/content/drive/MyDrive/Google AI Studio/story/images/\"+file_name+file_extension\n",
        "                        image_paths.append(image_path)\n",
        "                        break\n",
        "                    else:\n",
        "                        print(chunk.text)\n",
        "                        success = True\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2  # Increase delay exponentially\n",
        "                retries -= 1\n",
        "\n",
        "        time.sleep(6)  # Normal delay to respect API rate limit\n",
        "    return image_paths\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_images=generate(rewritten_scenes)"
      ],
      "metadata": {
        "id": "dnhRz-nri8w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_voiceover_dir ='/content/drive/MyDrive/Google AI Studio/story/voiceover'\n",
        "def generate_voiceovers(scenes, output_folder=drive_voiceover_dir):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    paths = []\n",
        "    for i, scene in enumerate(scenes):\n",
        "        tts = gTTS(scene, lang=\"en\", slow=False)\n",
        "        path = os.path.join(output_folder, f\"voiceover_{i+1}.mp3\")\n",
        "        tts.save(path)\n",
        "        paths.append(path)\n",
        "    return paths\n"
      ],
      "metadata": {
        "id": "YXLT5wYrtP3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_video_path ='/content/drive/MyDrive/Google AI Studio/story/video.mp4'\n",
        "def create_video(image_paths, voiceover_paths, output_video=drive_video_path, fps=1):\n",
        "    clips = []\n",
        "    for img_path, audio_path in zip(image_paths, voiceover_paths):\n",
        "        image_clip = ImageClip(img_path).set_duration(AudioFileClip(audio_path).duration).set_audio(AudioFileClip(audio_path))\n",
        "        clips.append(image_clip)\n",
        "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
        "    final_clip.write_videofile(output_video, fps=fps, codec=\"libx264\")\n",
        "voiceovers = generate_voiceovers(scenes)\n",
        "create_video(generate_images, voiceovers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx-Tg7fMt1JV",
        "outputId": "07fb17fc-31db-440c-e77d-ef3727dd3fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/drive/MyDrive/Google AI Studio/story/video.mp4.\n",
            "MoviePy - Writing audio in videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/drive/MyDrive/Google AI Studio/story/video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/MyDrive/Google AI Studio/story/video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpLp1EzF_3ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}